{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "_NM0E7BQGvC0",
        "-XgUD5vyIws2",
        "m26tQFsM_c_o",
        "2YmpqvZH_vLO",
        "z57aU8e-GdiX",
        "yvx5z4_nHghW",
        "4LcCJdkmHo8U",
        "5cX0rn66H75p",
        "qIBO7airL99o"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85b9e0e3e55c49b7a0dda6e99c666768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9777ea71d9a24f15a834b3946ff6a8e9",
              "IPY_MODEL_367765a6093147f18979d6e7f2dcf787",
              "IPY_MODEL_52f129019f1b4fe39c7720139fa873c9"
            ],
            "layout": "IPY_MODEL_41adf61fdafe44ed93351c995a874434"
          }
        },
        "9777ea71d9a24f15a834b3946ff6a8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a23da71c5c64f089f2c1c1c85ebd34c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3aee8ed009e84429af195e3e7e270a47",
            "value": "Map:‚Äá100%"
          }
        },
        "367765a6093147f18979d6e7f2dcf787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b41daf360534ef2993cff04c77a655d",
            "max": 4469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e323a6a89a94a378b3134623d4469b8",
            "value": 4469
          }
        },
        "52f129019f1b4fe39c7720139fa873c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41d4e7701b084b58bf327b11a94b8f6a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_db5b8301cda34e5ab704b036057d17bc",
            "value": "‚Äá4469/4469‚Äá[00:02&lt;00:00,‚Äá1665.32‚Äáexamples/s]"
          }
        },
        "41adf61fdafe44ed93351c995a874434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a23da71c5c64f089f2c1c1c85ebd34c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aee8ed009e84429af195e3e7e270a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b41daf360534ef2993cff04c77a655d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e323a6a89a94a378b3134623d4469b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41d4e7701b084b58bf327b11a94b8f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5b8301cda34e5ab704b036057d17bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdelaVilla/MORS/blob/main/Sesion_5_MORS_Clasificaci%C3%B3n_binaria_con_Transformers_y_corpus_HateEval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuaderno hecho para el grupo **I2C** por los profesores Jacinto Mata y Victoria Pach√≥n.\n",
        "\n",
        "*Tras cada secci√≥n aparece un comentario aclaratoio que explica l√≠nea a l√≠nea el proceso seguido.*"
      ],
      "metadata": {
        "id": "DZnVV2NU15UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Importar librer√≠as**"
      ],
      "metadata": {
        "id": "_NM0E7BQGvC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers\n",
        "!pip install --upgrade datasets transformers"
      ],
      "metadata": {
        "id": "IWkoEOzsGyGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55cfa1b8-cdce-4e41-c06b-c36713e293fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c765ea76"
      },
      "source": [
        "## **Explicaci√≥n del Cuaderno Paso a Paso**\n",
        "\n",
        "### **1. Importar Librer√≠as**\n",
        "\n",
        "Esta secci√≥n instala y carga las librer√≠as necesarias para el proyecto. Es crucial tener las versiones correctas de las librer√≠as `datasets` y `transformers`, ya que son fundamentales para el procesamiento de datos y la construcci√≥n del modelo BERT.\n",
        "\n",
        "*   `!pip install transformers==4.30.0 datasets==2.10.0`: Este comando se asegura de instalar versiones espec√≠ficas de las librer√≠as `transformers` y `datasets`. Es importante usar versiones compatibles para evitar problemas de compatibilidad y errores que puedan surgir de cambios en la API entre diferentes versiones. La versi√≥n `4.30.0` de `transformers` y `2.10.0` de `datasets` son versiones estables y conocidas por funcionar bien juntas en tareas de procesamiento de lenguaje natural con modelos como BERT."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Wu-kiXQCCLU5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e40a162d"
      },
      "source": [
        "*   `import pandas as pd`: Importa la librer√≠a `pandas`, que es una herramienta muy potente para la manipulaci√≥n y an√°lisis de datos en formato de tablas (DataFrames).\n",
        "*   `import re`: Importa el m√≥dulo `re`, que proporciona operaciones con expresiones regulares, √∫til para el preprocesamiento de texto.\n",
        "*   `from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback`: Importa componentes espec√≠ficos de la librer√≠a `transformers`:\n",
        "    *   `BertTokenizer`: Se encarga de convertir el texto en un formato que el modelo BERT pueda entender.\n",
        "    *   `BertForSequenceClassification`: La clase principal para el modelo BERT adaptado a tareas de clasificaci√≥n de secuencias.\n",
        "    *   `Trainer`: Una clase de utilidad que facilita el bucle de entrenamiento, evaluaci√≥n y predicci√≥n de modelos de Transformers.\n",
        "    *   `TrainingArguments`: Define los hiperpar√°metros y configuraciones para el entrenamiento del modelo.\n",
        "    *   `EarlyStoppingCallback`: Una herramienta para detener el entrenamiento si la m√©trica de evaluaci√≥n no mejora despu√©s de un cierto n√∫mero de √©pocas, evitando el sobreajuste.\n",
        "*   `import torch`: Importa la librer√≠a `torch`, que es el framework de aprendizaje profundo subyacente utilizado por `transformers`.\n",
        "*   `from sklearn.model_selection import train_test_split`: Importa la funci√≥n `train_test_split` de `scikit-learn`, que se utiliza para dividir el conjunto de datos en subconjuntos de entrenamiento y prueba.\n",
        "*   `from torch.utils.data import DataLoader, Dataset`: Importa clases de `PyTorch` para trabajar con conjuntos de datos y cargadores de datos, que permiten manejar grandes vol√∫menes de datos de manera eficiente durante el entrenamiento.\n",
        "*   `from sklearn.metrics import classification_report`: Importa la funci√≥n `classification_report` de `scikit-learn` para generar un informe detallado de las m√©tricas de clasificaci√≥n (precisi√≥n, recall, f1-score) del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXTvYwgjEnGv",
        "outputId": "4897658e-bcb8-4fb9-9425-bf9bf07966f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Cargar Dataset**"
      ],
      "metadata": {
        "id": "-XgUD5vyIws2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el dataset desde un archivo CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/corpus/HateEval/train_es.tsv', sep='\\t', usecols =[\"text\",\"HS\"])\n",
        "# Mostramos los primeros registros para verificar que los datos se cargaron correctamente\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L77QPA27JC9_",
        "outputId": "5869e5fa-610d-4950-d346-3cd0bef36b1e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  HS\n",
            "0  Easyjet quiere duplicar el n√∫mero de mujeres p...   1\n",
            "1  El gobierno debe crear un control estricto de ...   1\n",
            "2  Yo veo a mujeres destruidas por acoso laboral ...   0\n",
            "3  ‚Äî Yo soy respetuoso con los dem√°s, s√≥lamente l...   0\n",
            "4  Antonio Caballero y como ser de mal gusto e ig...   0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "945f0602"
      },
      "source": [
        "### **2. Cargar Dataset**\n",
        "\n",
        "Esta secci√≥n se enfoca en cargar el conjunto de datos principal para el entrenamiento y evaluaci√≥n del modelo. El dataset se carga desde un archivo CSV ubicado en Google Drive, lo que requiere montar primero la unidad de Drive en Colab.\n",
        "\n",
        "*   `from google.colab import drive` y `drive.mount('/content/drive')`: Estas l√≠neas son est√°ndar en Google Colab para permitir que el cuaderno acceda a los archivos almacenados en tu Google Drive. Al ejecutar `drive.mount()`, se te pedir√° que autorices el acceso.\n",
        "\n",
        "*   `df = pd.read_csv('/content/drive/MyDrive/corpus/HateEval/train_es.tsv', sep='\\t', usecols=[\"text\",\"HS\"])`: Aqu√≠ se lee el archivo `train_es.tsv` (que es un archivo de valores separados por tabulaciones, `sep='\\t'`) utilizando `pandas`. Se especifican las columnas `\"text\"` y `\"HS\"` (que probablemente representa 'Hate Speech' o similar) para cargar solo los datos relevantes. `df` es el DataFrame de pandas que contendr√° nuestros datos.\n",
        "\n",
        "*   `print(df.head())`: Despu√©s de cargar los datos, esta l√≠nea muestra las primeras cinco filas del DataFrame para que puedas verificar que la carga se realiz√≥ correctamente y que los datos tienen el formato esperado.\n",
        "\n",
        "*   `df.columns = ['text', 'label']`: Se renombran las columnas del DataFrame para que sean m√°s descriptivas y coherentes con la terminolog√≠a de los modelos de clasificaci√≥n. `text` para el contenido textual y `label` para la categor√≠a o etiqueta (en este caso, si es discurso de odio o no).\n",
        "\n",
        "*   `value_counts = df['label'].value_counts()`: Esta l√≠nea calcula cu√°ntas instancias hay de cada valor √∫nico en la columna `label`. Es una forma r√°pida de ver la distribuci√≥n de las clases en el dataset (por ejemplo, cu√°ntos ejemplos son 'discurso de odio' y cu√°ntos no lo son). Esto es √∫til para identificar posibles desequilibrios de clases."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['text', 'label']\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9h-YKgL34J6l",
        "outputId": "03bd509a-9ec8-4d37-f065-16472a9ac443"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     Easyjet quiere duplicar el n√∫mero de mujeres p...      1\n",
              "1     El gobierno debe crear un control estricto de ...      1\n",
              "2     Yo veo a mujeres destruidas por acoso laboral ...      0\n",
              "3     ‚Äî Yo soy respetuoso con los dem√°s, s√≥lamente l...      0\n",
              "4     Antonio Caballero y como ser de mal gusto e ig...      0\n",
              "...                                                 ...    ...\n",
              "4464  @miriaan_ac @Linaveso_2105 @HumildesSquad_ C√ÅL...      1\n",
              "4465  @IvanDuque presidente en C√∫cuta , tenemos prob...      1\n",
              "4466              - Callat√© Visto Que Te Dejo En Putaüé§üé∂      0\n",
              "4467  -¬øporque los hombres se casan con las mujeres?...      1\n",
              "4468  ‚Äî No hay nada m√°s lento que un caracol. ‚Äî C√°ll...      0\n",
              "\n",
              "[4469 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04afc12f-c2db-4370-86e1-fb557f922f17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Easyjet quiere duplicar el n√∫mero de mujeres p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>El gobierno debe crear un control estricto de ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yo veo a mujeres destruidas por acoso laboral ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‚Äî Yo soy respetuoso con los dem√°s, s√≥lamente l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Antonio Caballero y como ser de mal gusto e ig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4464</th>\n",
              "      <td>@miriaan_ac @Linaveso_2105 @HumildesSquad_ C√ÅL...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4465</th>\n",
              "      <td>@IvanDuque presidente en C√∫cuta , tenemos prob...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4466</th>\n",
              "      <td>- Callat√© Visto Que Te Dejo En Putaüé§üé∂</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4467</th>\n",
              "      <td>-¬øporque los hombres se casan con las mujeres?...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4468</th>\n",
              "      <td>‚Äî No hay nada m√°s lento que un caracol. ‚Äî C√°ll...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4469 rows √ó 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04afc12f-c2db-4370-86e1-fb557f922f17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04afc12f-c2db-4370-86e1-fb557f922f17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04afc12f-c2db-4370-86e1-fb557f922f17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47e29f1f-f08a-47da-9b9f-1240e7bdd107\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47e29f1f-f08a-47da-9b9f-1240e7bdd107')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47e29f1f-f08a-47da-9b9f-1240e7bdd107 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3b353ba8-801f-4413-ba40-3287379eb060\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3b353ba8-801f-4413-ba40-3287379eb060 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4469,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4469,\n        \"samples\": [\n          \"Me ha parecido una puta mierda que no se cumpla esto,porque se merecian cantar esto. Si,lo digo. https://t.co/jQXulXOf7i\",\n          \"Racismo es que no haya g\\u00fceros en aprietos. \\ud83d\\ude44\\ud83d\\ude06\",\n          \"Desde el New York Times y The New Yorker public\\u00f3 por primera vez las acusaciones de acoso sexual y violaci\\u00f3n contra Harvey Weinstein por Rose McGowan, Gwyneth Paltrow, Ashley Judd y docenas de otros, el productor desgracia ha sido despedido de su empresa y fiscal d ...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vemos cuantas instancias hay de cada tipo en el dataset\n",
        "\n",
        "value_counts = df['label'].value_counts()\n",
        "value_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "9YUtq6owS3lw",
        "outputId": "fd6c6b17-4d6c-46ea-9325-eed50d8e80a1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    2631\n",
              "1    1838\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NBU6t4gsPkSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Preprocesado b√°sico**"
      ],
      "metadata": {
        "id": "m26tQFsM_c_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_lowercase(tweet):\n",
        "    \"\"\"Takes a string and converts all characters to lowercase\"\"\"\n",
        "    return tweet.lower()"
      ],
      "metadata": {
        "id": "GCan2CzrDGyc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos el preprocesamiento al texto de nuestro DataFrame\n",
        "df['text'] = df['text'].apply(to_lowercase)"
      ],
      "metadata": {
        "id": "qiqphSCDDH9N"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobamos si ha funcionado el preprocesado"
      ],
      "metadata": {
        "id": "tXya40u-VqiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostramos dos filas\n",
        "\n",
        "print(df.iloc[17]['text'])\n",
        "print(df.iloc[24]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saPFZJ2oVtlD",
        "outputId": "feafaa6d-a218-4721-9281-5d7a7bf94fb7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vamoooo la puta madre se lo merec√≠a tanto esfuerzo y haber pasado tantos tel√©fonos necesit√°bamos este descanso #soltartenoest√°enmisplanesmica\n",
            "si cualquier cosa es violaci√≥n o acoso, se minimizan la violaci√≥n y el acoso. por lo tanto, pierden las v√≠ctimas de las mierdas que se dedican a violar y/o acosar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "040e1730"
      },
      "source": [
        "## **3. Preprocesado b√°sico**\n",
        "\n",
        "Esta secci√≥n se centra en las primeras etapas de limpieza del texto, que son fundamentales para preparar los datos antes de la tokenizaci√≥n y el entrenamiento del modelo. Un preprocesamiento adecuado puede mejorar significativamente el rendimiento del modelo.\n",
        "\n",
        "*   `def to_lowercase(tweet): return tweet.lower()`: Define una funci√≥n simple llamada `to_lowercase` que toma una cadena de texto (`tweet`) y devuelve la misma cadena convertida completamente a min√∫sculas. Esta es una pr√°ctica com√∫n en el procesamiento de lenguaje natural para estandarizar el texto y asegurar que, por ejemplo, 'Hola' y 'hola' se traten como la misma palabra.\n",
        "\n",
        "*   `df['text'] = df['text'].apply(to_lowercase)`: Aplica la funci√≥n `to_lowercase` a cada entrada de la columna `text` de tu DataFrame `df`. El m√©todo `.apply()` de pandas es muy √∫til para aplicar una funci√≥n a todos los elementos de una serie (columna) de un DataFrame.\n",
        "\n",
        "*   **Comprobaci√≥n del preprocesado:** Las l√≠neas siguientes en el cuaderno (`print(df.iloc[17]['text'])` y `print(df.iloc[24]['text'])`) est√°n dise√±adas para mostrar c√≥mo ha quedado el texto despu√©s de aplicar la conversi√≥n a min√∫sculas, permitiendo verificar que el preprocesamiento se realiz√≥ correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Conversi√≥n a Dataset y Tokenizaci√≥n**"
      ],
      "metadata": {
        "id": "2YmpqvZH_vLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos el tokenizador de BERT para convertir el texto en vectores que pueda entender el modelo, truncando o rellenando hasta la longitud m√°xima establecida."
      ],
      "metadata": {
        "id": "3MskL3KJ_3k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el tokenizador de BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Convertir el DataFrame a Dataset\n",
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Definir la funci√≥n de tokenizaci√≥n\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "# Aplicar la tokenizaci√≥n al Dataset\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Convertir las columnas necesarias a formato tensor de PyTorch\n",
        "tokenized_dataset = tokenized_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# Verificar el dataset tokenizado\n",
        "print(tokenized_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382,
          "referenced_widgets": [
            "85b9e0e3e55c49b7a0dda6e99c666768",
            "9777ea71d9a24f15a834b3946ff6a8e9",
            "367765a6093147f18979d6e7f2dcf787",
            "52f129019f1b4fe39c7720139fa873c9",
            "41adf61fdafe44ed93351c995a874434",
            "9a23da71c5c64f089f2c1c1c85ebd34c",
            "3aee8ed009e84429af195e3e7e270a47",
            "6b41daf360534ef2993cff04c77a655d",
            "1e323a6a89a94a378b3134623d4469b8",
            "41d4e7701b084b58bf327b11a94b8f6a",
            "db5b8301cda34e5ab704b036057d17bc"
          ]
        },
        "id": "ggaaKArW_1iH",
        "outputId": "7320029b-fbc2-4334-8714-a105f87e7896"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4469 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85b9e0e3e55c49b7a0dda6e99c666768"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': tensor(1), 'input_ids': tensor([  101,  3733, 15759, 21864,  7869,  4241, 24759,  5555,  2099,  3449,\n",
            "        16371,  5017,  2080,  2139, 14163, 20009,  2229,  4405,  2080,  1005,\n",
            "        12297,  2015, 10722, 11498,  9706,  2906, 10010,  3449, 20704,  3258,\n",
            "         1012,  1012,  8299,  1024,  1013,  1013,  1056,  1012,  2522,  1013,\n",
            "         4805, 11231, 13687,  2213,  2692,  2683,  2595,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3d0dca2"
      },
      "source": [
        "## **4. Conversi√≥n a Dataset y Tokenizaci√≥n**\n",
        "\n",
        "En esta secci√≥n, el texto se prepara para ser introducido en el modelo BERT. Esto implica dos pasos principales: la conversi√≥n del DataFrame de pandas a un objeto `Dataset` de Hugging Face y la tokenizaci√≥n del texto.\n",
        "\n",
        "*   `tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')`: Aqu√≠ se carga un tokenizador pre-entrenado espec√≠fico para el modelo `bert-base-uncased`. El tokenizador es esencial para dividir el texto en \"tokens\" (palabras o subpalabras), a√±adir tokens especiales (`[CLS]`, `[SEP]`), y convertir estos tokens en IDs num√©ricos que el modelo entiende. `bert-base-uncased` se refiere a la versi√≥n base de BERT, que no distingue entre may√∫sculas y min√∫sculas.\n",
        "\n",
        "*   `from datasets import Dataset` y `dataset = Dataset.from_pandas(df)`: La librer√≠a `datasets` de Hugging Face es muy eficiente para manejar grandes conjuntos de datos en el contexto del aprendizaje profundo. Esta l√≠nea convierte el DataFrame de pandas (`df`) que contiene nuestro texto y etiquetas en un objeto `Dataset` de Hugging Face, lo cual es el formato preferido para trabajar con los modelos de la librer√≠a `transformers`.\n",
        "\n",
        "*   `def tokenize_function(example): return tokenizer(example[\"text\"], padding='max_length', truncation=True, max_length=128)`: Se define una funci√≥n para tokenizar el texto. Esta funci√≥n toma un ejemplo del dataset, extrae el texto (`example[\"text\"]`), y lo tokeniza usando el `tokenizer` cargado. Los argumentos importantes son:\n",
        "    *   `padding='max_length'`: Asegura que todas las secuencias tokenizadas tengan la misma longitud, rellenando con ceros si son m√°s cortas que `max_length`.\n",
        "    *   `truncation=True`: Si una secuencia es m√°s larga que `max_length`, se trunca para ajustarse.\n",
        "    *   `max_length=128`: Define la longitud m√°xima de la secuencia de tokens. Este valor es importante porque los modelos BERT tienen un l√≠mite en la longitud de entrada.\n",
        "\n",
        "*   `tokenized_dataset = dataset.map(tokenize_function, batched=True)`: Esta l√≠nea aplica la funci√≥n `tokenize_function` a todo el `dataset`. El argumento `batched=True` permite que el tokenizador procese m√∫ltiples ejemplos a la vez, lo que es mucho m√°s eficiente.\n",
        "\n",
        "*   `tokenized_dataset = tokenized_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])`: Despu√©s de la tokenizaci√≥n, se configuran las columnas necesarias (`input_ids`, `attention_mask`, y `label`) para que est√©n en formato `torch.Tensor`. Esto es fundamental ya que `torch` es el backend de PyTorch que utiliza `transformers`.\n",
        "\n",
        "*   `print(tokenized_dataset[0])`: Finalmente, se imprime el primer ejemplo del `tokenized_dataset` para verificar c√≥mo se ve un ejemplo despu√©s de la tokenizaci√≥n, mostrando los `input_ids` (IDs num√©ricos de los tokens), la `attention_mask` (para indicar qu√© tokens son reales y cu√°les son relleno) y la `label`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Divisi√≥n en Conjuntos de Entrenamiento, validaci√≥n y test**"
      ],
      "metadata": {
        "id": "z57aU8e-GdiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos el conjunto de entrenamiento en 65% train, 15% validaci√≥n y 20% test"
      ],
      "metadata": {
        "id": "W-PL32LsNukq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir en entrenamiento (80%) y test (20%)\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_data = train_test_split['train']\n",
        "test_data = train_test_split['test']\n",
        "\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en entrenamiento (70%) y validaci√≥n (30%)\n",
        "train_valid_split = train_data.train_test_split(test_size=0.3, seed=42)\n",
        "train_data = train_valid_split['train']\n",
        "valid_data = train_valid_split['test']"
      ],
      "metadata": {
        "id": "tqCnAS5dRlG2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntz5qTO3Rs0F",
        "outputId": "d60c1841-3628-4967-9bbf-92a65b001069"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 2502\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib1Nto-yRxtV",
        "outputId": "ba326213-2f7a-4ff7-d1fe-4d5d0224bb48"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 1073\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9C8oxprRzfo",
        "outputId": "f019e781-f885-4c3f-cb3d-5e49745efe0e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 894\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "987ece05"
      },
      "source": [
        "## **5. Divisi√≥n en Conjuntos de Entrenamiento, validaci√≥n y test**\n",
        "\n",
        "Esta secci√≥n es crucial para asegurar una evaluaci√≥n imparcial del modelo. El dataset tokenizado se divide en tres partes:\n",
        "\n",
        "*   **Conjunto de Entrenamiento (Train Set):** Utilizado para entrenar el modelo. El modelo aprende de estos datos.\n",
        "*   **Conjunto de Validaci√≥n (Validation Set):** Utilizado durante el entrenamiento para ajustar hiperpar√°metros y detectar el sobreajuste. El rendimiento del modelo en este conjunto gu√≠a las decisiones durante el entrenamiento.\n",
        "*   **Conjunto de Prueba (Test Set):** Utilizado para la evaluaci√≥n final del modelo, una vez que el entrenamiento ha concluido. Estos datos son completamente nuevos para el modelo y proporcionan una estimaci√≥n realista de su rendimiento en datos no vistos.\n",
        "\n",
        "El proceso de divisi√≥n se realiza en dos pasos:\n",
        "\n",
        "1.  **Divisi√≥n inicial en Entrenamiento y Prueba:**\n",
        "    *   `train_test_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)`: El `tokenized_dataset` se divide por primera vez. El `test_size=0.2` indica que el 20% de los datos se asignar√° al conjunto de prueba, y el 80% restante al conjunto de entrenamiento inicial. `seed=42` asegura que la divisi√≥n sea reproducible.\n",
        "    *   `train_data = train_test_split['train']`: Los datos del 80% se asignan a `train_data`.\n",
        "    *   `test_data = train_test_split['test']`: Los datos del 20% se asignan a `test_data`.\n",
        "\n",
        "2.  **Divisi√≥n del Conjunto de Entrenamiento inicial en Entrenamiento y Validaci√≥n:**\n",
        "    *   `train_valid_split = train_data.train_test_split(test_size=0.3, seed=42)`: El `train_data` (el 80% original) se divide nuevamente. Esta vez, el `test_size=0.3` significa que el 30% de este 80% (lo que representa el 24% del dataset total: 0.3 * 0.8 = 0.24) se utilizar√° para validaci√≥n. El `seed=42` se mantiene para reproducibilidad.\n",
        "    *   `train_data = train_valid_split['train']`: El 70% del `train_data` inicial (56% del total: 0.7 * 0.8 = 0.56) se convierte en el conjunto de entrenamiento final.\n",
        "    *   `valid_data = train_valid_split['test']`: El 30% del `train_data` inicial (24% del total) se convierte en el conjunto de validaci√≥n.\n",
        "\n",
        "Al final, los datos se dividen aproximadamente en:\n",
        "*   **Entrenamiento:** 56% del total (originalmente 65% + 15% + 20%, se reajusta a 56% train, 24% validation, 20% test).\n",
        "*   **Validaci√≥n:** 24% del total.\n",
        "*   **Prueba:** 20% del total.\n",
        "\n",
        "Las impresiones de `train_data`, `valid_data`, y `test_data` que ves en las celdas siguientes (`Ntz5qTO3Rs0F`, `Ib1Nto-yRxtV`, `B9C8oxprRzfo`) muestran un resumen de cada `Dataset`, incluyendo las caracter√≠sticas disponibles y el n√∫mero de filas en cada conjunto, confirmando el resultado de las divisiones."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Carga del modelo BERT para clasificaci√≥n**"
      ],
      "metadata": {
        "id": "yvx5z4_nHghW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el modelo preentrenado BertForSequenceClassification con dos etiquetas de salida."
      ],
      "metadata": {
        "id": "iEBUodB_Hsm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHSmu6DMHm0R",
        "outputId": "d8f42715-ee58-44a4-ca10-95034dda879e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "089a8c46"
      },
      "source": [
        "## **6. Carga del modelo BERT para clasificaci√≥n**\n",
        "\n",
        "Esta secci√≥n se encarga de cargar el modelo BERT que utilizaremos para la tarea de clasificaci√≥n de secuencias.\n",
        "\n",
        "*   `model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)`: Esta l√≠nea es clave. Aqu√≠:\n",
        "    *   `BertForSequenceClassification`: Es la clase de modelo de la librer√≠a `transformers` espec√≠ficamente dise√±ada para tareas de clasificaci√≥n de secuencias utilizando BERT.\n",
        "    *   `from_pretrained('bert-base-uncased')`: Carga los pesos pre-entrenados del modelo `bert-base-uncased`. `bert-base-uncased` es una versi√≥n de BERT que ha sido entrenada con un gran corpus de texto y no distingue entre may√∫sculas y min√∫sculas (de ah√≠ 'uncased'). Utilizar un modelo pre-entrenado es una pr√°ctica com√∫n en NLP, ya que permite aprovechar el conocimiento ling√º√≠stico adquirido durante su pre-entrenamiento en una tarea general de comprensi√≥n del lenguaje.\n",
        "    *   `num_labels=2`: Indica que el modelo se est√° configurando para una tarea de clasificaci√≥n binaria, donde hay dos posibles etiquetas de salida (en nuestro caso, probablemente 0 para 'no discurso de odio' y 1 para 'discurso de odio'). El modelo ajustar√° su capa de clasificaci√≥n final para tener dos neuronas de salida."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Configuraci√≥n de par√°metros de entrenamiento**"
      ],
      "metadata": {
        "id": "4LcCJdkmHo8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuramos los par√°metros de entrenamiento, incluyendo el n√∫mero de √©pocas y el tama√±o del lote."
      ],
      "metadata": {
        "id": "dx-C8DpSHzZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',       # Carpeta para guardar los resultados\n",
        "    num_train_epochs=4,           # N√∫mero de √©pocas\n",
        "    per_device_train_batch_size=8,  # Tama√±o del lote de entrenamiento\n",
        "    per_device_eval_batch_size=8,  # Tama√±o del lote de evaluaci√≥n\n",
        "    eval_strategy=\"epoch\",   # Evaluar al final de cada √©poca\n",
        "    logging_dir='./logs',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'f1',\n",
        "    save_strategy = 'epoch'\n",
        ")"
      ],
      "metadata": {
        "id": "jfkRm5ruHxlQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ebbba09"
      },
      "source": [
        "## **7. Configuraci√≥n de par√°metros de entrenamiento**\n",
        "\n",
        "Esta secci√≥n define los argumentos y configuraciones que guiar√°n el proceso de entrenamiento del modelo BERT.\n",
        "\n",
        "*   `training_args = TrainingArguments(...)`: Se crea un objeto `TrainingArguments` que encapsula todos los hiperpar√°metros y la configuraci√≥n para el `Trainer`. Analicemos los argumentos clave:\n",
        "    *   `output_dir='./results'`: Especifica el directorio donde se guardar√°n los resultados del entrenamiento, como los checkpoints del modelo y las m√©tricas de evaluaci√≥n.\n",
        "    *   `num_train_epochs=4`: Define el n√∫mero total de √©pocas (pasadas completas sobre el conjunto de datos de entrenamiento) que el modelo realizar√°.\n",
        "    *   `per_device_train_batch_size=8`: Establece el tama√±o del lote para el entrenamiento en cada dispositivo (GPU/CPU). Lotes m√°s peque√±os pueden requerir m√°s tiempo de entrenamiento pero pueden ser √∫tiles con memoria limitada o para mejorar la generalizaci√≥n.\n",
        "    *   `per_device_eval_batch_size=8`: Establece el tama√±o del lote para la evaluaci√≥n en cada dispositivo.\n",
        "    *   `eval_strategy=\"epoch\"`: Indica que la evaluaci√≥n del modelo se realizar√° al final de cada √©poca de entrenamiento. Tambi√©n podr√≠a ser por pasos (`\"steps\"`).\n",
        "    *   `logging_dir='./logs'`: Especifica el directorio donde se guardar√°n los logs del entrenamiento, √∫tiles para monitorear el progreso con herramientas como TensorBoard.\n",
        "    *   `load_best_model_at_end=True`: Configura el `Trainer` para que, al finalizar el entrenamiento, cargue autom√°ticamente la versi√≥n del modelo que obtuvo el mejor rendimiento en el conjunto de validaci√≥n (seg√∫n `metric_for_best_model`).\n",
        "    *   `metric_for_best_model='f1'`: Define la m√©trica que el `Trainer` usar√° para determinar cu√°l es el \"mejor\" modelo. En este caso, es el F1-score, que es una m√©trica com√∫n para problemas de clasificaci√≥n, especialmente cuando hay desequilibrio de clases. El `Trainer` intentar√° maximizar esta m√©trica.\n",
        "    *   `save_strategy=\"epoch\"`: Especifica que el modelo se guardar√° (checkpoint) al final de cada √©poca. Esto permite recuperar el entrenamiento si se interrumpe y comparar el rendimiento de diferentes √©pocas."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Entrenamiento y evaluaci√≥n del modelo**"
      ],
      "metadata": {
        "id": "5cX0rn66H75p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos Trainer para entrenar y evaluar el modelo con el conjunto de entrenamiento y el de validaci√≥n."
      ],
      "metadata": {
        "id": "5Z9hjhk7IDPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Definir la funci√≥n compute_metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    preds = predictions.argmax(axis=-1)\n",
        "\n",
        "    # Calcular las m√©tricas usando las predicciones y etiquetas\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # Modelo a entrenar\n",
        "    args=training_args,                  # Argumentos de entrenamiento\n",
        "    train_dataset=train_data,            # Conjunto de entrenamiento\n",
        "    eval_dataset=valid_data,             # Conjunto de evaluaci√≥n\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "# Ejecutar el entrenamiento\n",
        "trainer.train()\n",
        "\n",
        "# Evaluar el modelo\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "bEmKbIr9IBkq",
        "outputId": "f9c04cb1-e1b6-4a21-bcfd-856514514c6a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmdelavilla\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251115_162735-921pzy4r</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mdelavilla/huggingface/runs/921pzy4r' target=\"_blank\">winter-resonance-1</a></strong> to <a href='https://wandb.ai/mdelavilla/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mdelavilla/huggingface' target=\"_blank\">https://wandb.ai/mdelavilla/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mdelavilla/huggingface/runs/921pzy4r' target=\"_blank\">https://wandb.ai/mdelavilla/huggingface/runs/921pzy4r</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1252' max='1252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1252/1252 05:10, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.629910</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.649025</td>\n",
              "      <td>0.529545</td>\n",
              "      <td>0.583229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.598800</td>\n",
              "      <td>0.508991</td>\n",
              "      <td>0.792171</td>\n",
              "      <td>0.780362</td>\n",
              "      <td>0.686364</td>\n",
              "      <td>0.730351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.598800</td>\n",
              "      <td>0.517332</td>\n",
              "      <td>0.785648</td>\n",
              "      <td>0.738636</td>\n",
              "      <td>0.738636</td>\n",
              "      <td>0.738636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.403500</td>\n",
              "      <td>0.828000</td>\n",
              "      <td>0.791240</td>\n",
              "      <td>0.762136</td>\n",
              "      <td>0.713636</td>\n",
              "      <td>0.737089</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [135/135 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5173322558403015,\n",
              " 'eval_accuracy': 0.7856477166821995,\n",
              " 'eval_precision': 0.7386363636363636,\n",
              " 'eval_recall': 0.7386363636363636,\n",
              " 'eval_f1': 0.7386363636363636,\n",
              " 'eval_runtime': 7.3043,\n",
              " 'eval_samples_per_second': 146.9,\n",
              " 'eval_steps_per_second': 18.482,\n",
              " 'epoch': 4.0}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbb272db"
      },
      "source": [
        "## **8. Entrenamiento y evaluaci√≥n del modelo**\n",
        "\n",
        "En esta secci√≥n, se configura y ejecuta el proceso de entrenamiento y evaluaci√≥n del modelo BERT utilizando la clase `Trainer` de la librer√≠a `transformers`.\n",
        "\n",
        "*   `from sklearn.metrics import accuracy_score, precision_recall_fscore_support`:\n",
        "    Se importan las m√©tricas necesarias de `scikit-learn` para evaluar el rendimiento del modelo.\n",
        "\n",
        "*   `def compute_metrics(eval_pred): ...`:\n",
        "    Se define una funci√≥n `compute_metrics` que el `Trainer` utilizar√° para calcular m√©tricas de evaluaci√≥n durante el entrenamiento y la evaluaci√≥n. Esta funci√≥n toma las predicciones (`predictions`) y las etiquetas reales (`labels`) del modelo. Dentro de la funci√≥n:\n",
        "    *   `preds = predictions.argmax(axis=-1)`: Convierte las logits (salidas crudas del modelo antes de la funci√≥n de activaci√≥n) en predicciones de clases, seleccionando la clase con la probabilidad m√°s alta.\n",
        "    *   `accuracy = accuracy_score(labels, preds)`: Calcula la precisi√≥n, que es la proporci√≥n de predicciones correctas.\n",
        "    *   `precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')`: Calcula la precisi√≥n, recall y F1-score. `average='binary'` se usa para problemas de clasificaci√≥n binaria, donde se calcula la m√©trica para la clase positiva (generalmente 1).\n",
        "    *   La funci√≥n devuelve un diccionario con estas m√©tricas.\n",
        "\n",
        "*   `trainer = Trainer(...)`:\n",
        "    Se inicializa el objeto `Trainer` con los siguientes par√°metros:\n",
        "    *   `model=model`: El modelo `BertForSequenceClassification` que hemos cargado previamente.\n",
        "    *   `args=training_args`: Los argumentos de entrenamiento definidos en la secci√≥n anterior (`TrainingArguments`).\n",
        "    *   `train_dataset=train_data`: El conjunto de datos de entrenamiento.\n",
        "    *   `eval_dataset=valid_data`: El conjunto de datos de validaci√≥n, que se usar√° para evaluar el modelo durante el entrenamiento y para la parada temprana.\n",
        "    *   `compute_metrics=compute_metrics`: La funci√≥n que hemos definido para calcular las m√©tricas.\n",
        "    *   `callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]`: Se a√±ade una callback de parada temprana. Esto significa que si la m√©trica de evaluaci√≥n (en este caso, 'f1' como se defini√≥ en `TrainingArguments`) no mejora durante 3 √©pocas consecutivas, el entrenamiento se detendr√° autom√°ticamente para evitar el sobreajuste.\n",
        "\n",
        "*   `trainer.train()`:\n",
        "    Inicia el proceso de entrenamiento del modelo. El `Trainer` gestionar√° el bucle de entrenamiento, la evaluaci√≥n peri√≥dica y el guardado del mejor modelo seg√∫n los `training_args`.\n",
        "\n",
        "*   `trainer.evaluate()`:\n",
        "    Despu√©s de que el entrenamiento ha finalizado, esta l√≠nea eval√∫a el modelo (normalmente el mejor modelo guardado si `load_best_model_at_end=True`) en el `eval_dataset` (conjunto de validaci√≥n) y muestra un resumen de las m√©tricas de rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. Prueba del modelo en nuevos textos**"
      ],
      "metadata": {
        "id": "qIBO7airL99o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos hacer predicciones en nuevos textos para evaluar el modelo."
      ],
      "metadata": {
        "id": "h2OGvS8QMFz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set and print the classification report\n",
        "\n",
        "test_results = trainer.predict(test_data)\n",
        "predictions = test_results.predictions.argmax(axis=-1)\n",
        "labels = test_results.label_ids\n",
        "\n",
        "print(predictions)\n",
        "#print(labels)\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "oUQkrWK4VCPo",
        "outputId": "90684997-f5f5-472d-8b95-b0444d3900d6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
            " 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1\n",
            " 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0\n",
            " 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1\n",
            " 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0\n",
            " 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0\n",
            " 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 1\n",
            " 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
            " 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 0\n",
            " 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0\n",
            " 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1\n",
            " 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0 0 0 0\n",
            " 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0\n",
            " 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1\n",
            " 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1\n",
            " 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0\n",
            " 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
            " 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1\n",
            " 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0\n",
            " 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0\n",
            " 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0\n",
            " 0 1 0 1 1 1]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.83       535\n",
            "           1       0.74      0.73      0.74       359\n",
            "\n",
            "    accuracy                           0.79       894\n",
            "   macro avg       0.78      0.78      0.78       894\n",
            "weighted avg       0.79      0.79      0.79       894\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f972b551"
      },
      "source": [
        "## **9. Prueba del modelo en nuevos textos**\n",
        "\n",
        "En esta secci√≥n, se utiliza el modelo entrenado para hacer predicciones en el conjunto de prueba (`test_data`) y se eval√∫a su rendimiento final utilizando un informe de clasificaci√≥n detallado.\n",
        "\n",
        "*   `test_results = trainer.predict(test_data)`:\n",
        "    *   El m√©todo `trainer.predict()` se utiliza para obtener las predicciones del modelo sobre el `test_data`.\n",
        "    *   Este m√©todo devuelve un objeto que contiene las `predictions` (las salidas del modelo, a menudo logits) y las `label_ids` (las etiquetas reales del conjunto de prueba).\n",
        "\n",
        "*   `predictions = test_results.predictions.argmax(axis=-1)`:\n",
        "    *   Las `predictions` obtenidas de `trainer.predict()` son t√≠picamente los *logits* (valores brutos antes de la funci√≥n de activaci√≥n final) para cada clase.\n",
        "    *   `.argmax(axis=-1)` se aplica para convertir estos logits en las etiquetas de clase predichas, seleccionando el √≠ndice (la clase) con el valor m√°s alto.\n",
        "\n",
        "*   `labels = test_results.label_ids`:\n",
        "    *   Esta l√≠nea simplemente asigna las etiquetas verdaderas del conjunto de prueba a la variable `labels` para facilitar su uso en la evaluaci√≥n.\n",
        "\n",
        "*   `print(predictions)`:\n",
        "    *   Imprime el array de las etiquetas predichas por el modelo para el conjunto de prueba.\n",
        "\n",
        "*   `print(classification_report(labels, predictions))`:\n",
        "    *   Finalmente, se utiliza la funci√≥n `classification_report` de `sklearn.metrics` para generar un informe de evaluaci√≥n completo.\n",
        "    *   Este informe incluye m√©tricas clave como: `precision`, `recall`, `f1-score` y `support` (el n√∫mero de instancias de cada clase) para cada clase, as√≠ como `accuracy` (precisi√≥n general), `macro avg` (promedio no ponderado de las m√©tricas por clase) y `weighted avg` (promedio ponderado por el n√∫mero de instancias por clase).\n",
        "    *   Este informe es fundamental para entender el rendimiento del modelo en el conjunto de prueba, especialmente en problemas con desequilibrio de clases, donde la precisi√≥n simple puede ser enga√±osa."
      ]
    }
  ]
}