{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0jaa7RKzNRM+ZHR7Flfe3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdelaVilla/MORS/blob/main/Sesion_transformers_MORS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial extraido y traducido de\n",
        "https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
        "\n",
        "En este tutorial vamos a usar Transformers para una tarea de Clasificación de textos, en este caso de análisis de sentimiento para determinar la etiqueta (positivo, negativo o neutral) a asignar a una secuencia de texto.\n",
        "\n",
        "Veremos:\n",
        "1. Como hacer un finetune (ajuste fino) a un modelo preentrenado (DistilBert) con un dataset (IMDB) para determinar si una 'review' de una película es positiva o negativa.\n",
        "2. Usaremos nuestro modelo ajustado para inferir nuevas predicciones.\n"
      ],
      "metadata": {
        "id": "VoX0fXugXmOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de empezar, instalemos las librerias necesarias"
      ],
      "metadata": {
        "id": "8SqbxukOY730"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKwJBFBVgdVI",
        "outputId": "a3cc0d19-ad61-4878-e07a-d0b1510ba804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es recomendable usar una cuenta de Hugging Face para subir y compartir nuestro modelo con la comunidad.\n",
        "\n",
        "Si no la tienes, create una cuenta y crea un token (de escritura). Introducelo para loguearte."
      ],
      "metadata": {
        "id": "EYs8ZlW8ZDNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "OhRD3nIggpIV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "8548d5b19b3f477e84a387249e1412d0",
            "158e53d063874016b2127749c0745594",
            "7f740f5fc83c43998d2ef6a683078383",
            "d0eaed9d64874efb940a55cf07dc2f19",
            "5a3849dd9f9c40219edbdbefb20f1f8d",
            "a66da45e748e44149805681853f208ec",
            "b04a716beb9f4918ae829c2c8c657cd6",
            "7634543e1b7a475ba81f8ba83ee4d622",
            "068fc150447f4455b912c4707bfcf8b1",
            "72fd70651e664c52aab0d3be79ca9021",
            "1c7f7ff574c74b7cb7847aff97da0b7a",
            "c92daec0bc2549c69d39d61434be658e",
            "66bcb19132f045c39503ee5e4fc0273d",
            "029431cbae074ff3ae3097b9a5f2a080",
            "b44b7cb241af43249e0f79905494f1e6",
            "5401594e5e0146cca3ed4d9b618f5ba7",
            "35cff5163e2a438fa0b7aa8a317a6f8a",
            "b3f5835dfc684dc0bf2f866a0f6a3bee",
            "256e0fb4d0bf4266ba21dd7915fffa2c",
            "aceaf5c749454e00861e61531c3e065f",
            "e34590391e3b42fe954b136c9ff87064",
            "7337ad22b3d84fa38947abb3f89783b5",
            "e9d2d6f520c942589223d60ab88742d8",
            "87a7d9a0729d40ae9bf86e6d8d718d7c",
            "24957227a1b44cc5af562cb660b9946d",
            "9d7781dd3315475b958d7c4f5fccd8fa",
            "fe01c007d8c24593990bef7e5777cc93",
            "b3084e64e08c4db7bc930d09b9567684",
            "64e142d60b194992b6a8e4efc319db6b",
            "5e8e4c7a57c24b2ca0a0be3dd5bb2c1c",
            "cd9ead11db6344169a32ef6bd65ee41b",
            "9f7c556ea4a4435098b16e18f39c220b"
          ]
        },
        "id": "FuAQdUxygrmX",
        "outputId": "9e5d9a99-bd2b-4e8f-9633-2fb6bdda4162"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8548d5b19b3f477e84a387249e1412d0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comencemos cargando el dataset IMDb desde la librería Datasets de HF"
      ],
      "metadata": {
        "id": "XqkCu2dhZbJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "b7e8bf97a76843dd9eb46ade2209c2fd",
            "1a6023096e474c22aa1d6543dc8eb5dc",
            "6df3b5c8d1ce4139b716a84409e12424",
            "a7f694b3d04445cea3bd5f56ddaf83ca",
            "f25f7a6ed773470190e78592790311c7",
            "8b9a20189b7a4e9f8ad61cc3447aea11",
            "cc917e0a47c6486d82eaec612bb3b161",
            "fbdc3a8ba5e24d5c8e75565865ecfe90",
            "f0d87cb7b9074d7fa7b659f8c8175cb9",
            "ba30b21204244942ad5047d10a388dcc",
            "941c43c3a7574f7e938c5f3a8baa7e8e",
            "ec77643c3455465d85d4a77f0ab53450",
            "ea9a4a1736a0459fafa12ee294414c4d",
            "1114a7fead9941d2bd4819aafa4052b4",
            "7d75e53d84564798a78f5c585a298bed",
            "04fade3d944c4adf8f9b1aa63c141040",
            "bb8a97fb57de43e8908a43e53f29ea3c",
            "537eb40ed1fd4f57bf303a08f9180314",
            "7069718396b748408e48ee93efac3469",
            "9ef1134b1e194b4e89ef0b953f47a0c9",
            "f26e5e074e79461a96aff22552b1ffcc",
            "66093ea5b8c7472a8e46cff79adcafe5",
            "d500f66e30984fd99fcfbd60519269fe",
            "539ed9091bb34cafbc7412f529439456",
            "9ee2fdd16bd84bd2ae496cb61af7d625",
            "e113cfe2b92f40058fa5e74d6d4fc9fd",
            "80cbbb5363e64e80abaa4d09a1ed8860",
            "c00b201215074154bba78fe5034d790d",
            "13db20f3ff74492ab861e2a84e8ed8d3",
            "fa49ae7a0426451d96957907af58c235",
            "f286c9e857944696a8adfd55423c7202",
            "cce79ad7df4f4948a2d7b5313923de28",
            "26bc7ce06f024fed92629593f8be2267",
            "7578a7f0da8f44789aaea2a5fb4d3ce7",
            "da9eb59b2be844bfa037bf8464262f11",
            "1530d11eadf54ce98ac50160bdc0be87",
            "386bac8487f54052a1400f672640b4a6",
            "b815289f66ab44f98d87da898d915237",
            "0080a1aef8384bfab6977382b4dc156e",
            "8719302fcfea45cf8631ffda492e0099",
            "d36851cb87d0417eb32916db443a31f9",
            "87a4be77f27844b49a1ca1aee9c95fd1",
            "59e4a2520c55489e80e4d5d82a0ce14b",
            "f3ef1d82c0644ee9bee1e202f6e09707",
            "e48c3d1a3eef4a39ac325b69f1c2507a",
            "4ee6a167d7114f1f85408b012b192848",
            "22721e7612f244dda190953ddf2d00d6",
            "712e2a1b5ffd451a9c26c1bce1b75ea8",
            "ddad5202cfb647949571413259596146",
            "3ee605951b884fd8bd9f3edb622433f5",
            "0a611adb956e469686e5c6feb406ea08",
            "4582d7678350433e8c2cf2321ff0edc8",
            "6508fedb3521446292c7cf795b4492ae",
            "ba7e47594ce844d2b6b646e9143bdaf5",
            "e5ce60ac6740401eb3017cabc48b782c",
            "bedbfc58ef0c43c09cd0dcd796d81906",
            "9241fe4b4b374cc0b405fe6cd13c7d35",
            "a6f4084fe50e40769528cdc19de9700b",
            "8dac6ce0ee7a4b8c8be7497f83d821a2",
            "932b96145e294af69cdf2f72fa7927eb",
            "b46e8a0594034879b21c2d743b4c23cc",
            "dedf14d0f49544aca572a8b0763b5ea3",
            "a8f28ecb06b1402cb4171718de77ee92",
            "d3563e3e261f4a01a8e4c966d4f25362",
            "09597941005b475980b4b7dce331dbf4",
            "ebc194712ce64e788c1d6a922f812481",
            "e8ba2ae0393843e9bafdae9b7d6998c2",
            "d70fdf049bea4351a83f4f560ff76299",
            "85e206a8328e4cde8b10cea62f37748d",
            "3481abeb1ce548e283d2cb890c72828f",
            "ef94aac051bf47f882829f562bc46710",
            "be373b51205540b8adef5a00f9654154",
            "4fecc826610e43cfa902b205f7f37d7d",
            "030ac556bf0345ec85e6a0c0b95eeebf",
            "758cc634eaf04fd48fa839c5a3821ae1",
            "53c8221b52f24f9eac161aaef5b5a9ba",
            "94497b08c01e44ab9e9ea46b5eb2d78a"
          ]
        },
        "id": "cDnRF9s4g31u",
        "outputId": "1bbc7b53-06da-4ca3-89d1-b351acd91274"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7e8bf97a76843dd9eb46ade2209c2fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec77643c3455465d85d4a77f0ab53450"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d500f66e30984fd99fcfbd60519269fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7578a7f0da8f44789aaea2a5fb4d3ce7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e48c3d1a3eef4a39ac325b69f1c2507a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bedbfc58ef0c43c09cd0dcd796d81906"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8ba2ae0393843e9bafdae9b7d6998c2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos un ejemplo del contenido del dataset IMDb.\n",
        "Hay dos campos en el dataset:\n",
        "text: el texto de la revisión que hace el usuario\n",
        "label: el valor con que se etiqueta, 0 para revisión negativa, 1 para positiva"
      ],
      "metadata": {
        "id": "i_SZfSaRZo0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb[\"test\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4QuDPz5g7k4",
        "outputId": "01d30150-b7ec-4be7-a665-68ddd83275de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preproceso\n",
        "\n",
        "Vamos a empezar cargando el tokenizador del modelo preentrenado 'Distilbert' para preprocesar el campo 'text'"
      ],
      "metadata": {
        "id": "nMXhzIoNaCJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "050f0f5051dc469387121d5c0ce12679",
            "1e3c78d2488648cf8feb37e9aa970d4d",
            "ee1eaf72e17c41289cf7a584355f1f81",
            "6938ed4e61324503a36c6093d7cda5d5",
            "ecaa822e718c40feb81aeb2abcc07de6",
            "e508218a3d5f471daf3d98209bc5a40a",
            "448addac34ce427b9b322cf4dd5c6a7b",
            "9bd6e6cfa70b462c88c6d5ad1c28328e",
            "54cc7a33006d49b4aa4deeb017fafeca",
            "d5bef676d20142639e7c036687d52f00",
            "0df16b4409cc4c989e0b88ba38b6ddd7",
            "c44f9517b1aa4e95ae9f4b135580a71a",
            "4544d95aa7a148bc9935e30c41d71635",
            "f0dd47273c1c4f00aeb1071ca7132961",
            "1468efb81bd74216aee5e572ab40b873",
            "3337aef4ad0b42b0aa6acf94415224c5",
            "ae44b309c8824eb09c16f7404eb34ef2",
            "58626d17fb1c459d9f82b510088e3171",
            "75de4bd311084c85ae830447da0d8189",
            "b81ca343f72944cca4385d1976c2804f",
            "cd8defc1b698413ab89a7ab2b7a5aa05",
            "16c7c311f11b4f808a7dcb662110ed45",
            "fba5dfb7c82d4bb38de15f451c700a24",
            "9ca3e83046554e00bd5b7893a6dc0748",
            "93cb9e1061324136b2df40af8acc46cb",
            "ca57bee090c8429a984ca61a76e632af",
            "b6b32368a72345f9873111eda20bee8f",
            "6038681aa20746a88a052d1531061dad",
            "6633c4bf93674c38bde59d7df78fb8cd",
            "527fe3a261f4499a9543c6af770c3a73",
            "e14edca88067469f93a27bdf1505af0f",
            "9042bffb73ae46e5907e1dce6d7456cd",
            "a0975e66d6ff4df6be76030b9f5f9e12",
            "16122255682347f791440b70911b5ed4",
            "28e1495bbe6e4abaa07cb83873ac10a4",
            "342056ba23744b32857849d64f1d74ba",
            "d16ea070ce834f3bacc2f2ec2cdfce16",
            "309f18ce8b5f4e7cac0cea77a83bf4db",
            "6ab6c238b1b645b7bda54b7ca1427066",
            "5ab05827903049269b3597a8292f00d6",
            "933db4bca76b4be7bf4ec9dc6e86b801",
            "a08c89e82c424e2d8c5f82abaa076009",
            "523f258524aa4cc4b2afec11471d7661",
            "a7da8a37b4a94faaa6bccff81eb16df2"
          ]
        },
        "id": "CFSP2YtchTW-",
        "outputId": "a7573458-74cb-4a5f-9a34-93af3cd28d5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "050f0f5051dc469387121d5c0ce12679"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c44f9517b1aa4e95ae9f4b135580a71a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fba5dfb7c82d4bb38de15f451c700a24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16122255682347f791440b70911b5ed4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una función de preprocesamiento para tokenizar texto y truncar secuencias para que no superen la longitud máxima de entrada de DistilBERT:"
      ],
      "metadata": {
        "id": "UFIvbKCHakqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "ywrLVdf_hasH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para aplicar la función de preprocesamiento a todo el conjunto de datos, usamos la función 'map' de la librería Datasets. Puede acelerar el mapeo estableciendo *batched=True* para procesar varios elementos del dataset a la vez:"
      ],
      "metadata": {
        "id": "HP06OvR5a3zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ba7e36229b924dd4887599fddba2165b",
            "103531549cdf4e9a91466859fd23214a",
            "b9de6255334a46118017e96a1cd89c65",
            "d1a7fe10139f4b179d620065402308fa",
            "6199b9c726404146be7441a9e2e73b5a",
            "30a38aa4e5ec46ed841a71fcc96b110e",
            "c2cfa4dd7fe74cdab46d8b3986098b1f",
            "e315aa84795c4b8ea3cabaf6d3bf4d41",
            "43f06ccf166d469884c49ff0bdab1c09",
            "d42fe7bd7bef4138bf09d151bc812ed3",
            "bfcbd6102e99407b87f0aba548c860ea",
            "c2c28711aa6345e9b1a6816729e360ec",
            "a1bf736b0e964f4abf70e1f68e157bb1",
            "f0c5eb08d1c347ebb738dc47e35167c5",
            "4bd2577c0da14f1b9af7710c49b153b0",
            "2a60aefbb2fa4fcaa0da123c913fd512",
            "c42e44e61abe4589b43f80a4f3ef75ec",
            "9f81a6e69a07484abff2ecd86deb19a7",
            "a38f6165cf0044249f2eb5de33cf44f2",
            "22dc272ac2524bd39faf966e847f8d4b",
            "e76ebd5613dd4efea4ad583010929109",
            "befa71041ddb4714aa1ff457b276efad",
            "29317f7627514d2a9966e9b1aee7f92f",
            "7534e814f5eb4c78abaa951124beb451",
            "b1beb917e6b648cc9721d1a078bda61e",
            "b914550ac504430ab2bec7c5562b19c3",
            "fc2a3998901b4850b80cec17d3c51c8c",
            "46b51bede021455a868562bf968767eb",
            "5d6ba0d8fb3d4afaa0e3cbf111c404f8",
            "77dcc231449941778c201e24cc9702bf",
            "c0e942c6dde94cfb86cefdb64f0566e5",
            "1494cb32001b427db186b509297dae6d",
            "5749832641a3456db11078d73f0fa879"
          ]
        },
        "id": "wh-OqWWqhevF",
        "outputId": "d40e130e-01c7-420a-a308-252939c88683"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba7e36229b924dd4887599fddba2165b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2c28711aa6345e9b1a6816729e360ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29317f7627514d2a9966e9b1aee7f92f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora creamos un lote de ejemplos usando DataCollatorWithPadding. Es más eficiente rellenar dinámicamente, uno a uno, los textos hasta la longitud más larga de un lote durante la clasificación, que rellenar de una vez todo el conjunto de datos hasta la longitud máxima.\n",
        "Estamos usando la librería TensorFlow."
      ],
      "metadata": {
        "id": "63CWodYvbaoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "roidB89Ghqp_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación\n",
        "\n",
        "Incluir una métrica durante el entrenamiento suele ser útil para evaluar el rendimiento del modelo. Vamos a cargar rápidamente un método de evaluación desde la librería *Evaluate*. Para esta tarea, cargamos la métrica *accuracy*:"
      ],
      "metadata": {
        "id": "qwuX6MhdcC2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d545b58d5a1a48a49d3f50ffba1facce",
            "f3f7566c5b254974aac289c6174cbf60",
            "d5d60703edf943f194fb4649b7dd59c2",
            "2ff09b906ca44b5a926e35c2265ebe4d",
            "f480fb860c8442729078ebfea008ab12",
            "843dd8a9ce754d908144957ae387b285",
            "e9d5fe8205d64e2ab857e76963d6941c",
            "c512b45de8f94abba034f04f513af66c",
            "d9b2972b70c94eb1bc556f3a941f5e49",
            "40b5ab4e46ed4adcaac5c624e3c5d9c9",
            "626b86a3f46447c9b1836a478be6ad5f"
          ]
        },
        "id": "rvrXQI1JiD4e",
        "outputId": "3eaac7cc-4cf7-47cb-8841-cfe3c6907ec8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d545b58d5a1a48a49d3f50ffba1facce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después creamos una función que pase sus predicciones y etiquetas para calcular la precisión:"
      ],
      "metadata": {
        "id": "KpfsqrtwchYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "iuyQGbvKiJGF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestra función *compute_metrics* está lista para funcionar. Volveremos a ella cuando configuremos el entrenamiento."
      ],
      "metadata": {
        "id": "IL-Q0Kqvc3ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento\n",
        "\n",
        "Antes de empezar a entrenar el modelo, creamos un mapa que nos convierta los identificadores esperados y sus etiquetas con id2label y label2id:"
      ],
      "metadata": {
        "id": "_aC-ZpiIdBk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ],
      "metadata": {
        "id": "4WCftgcUiL7O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ajustar un modelo en TensorFlow, comience configurando una función optimizadora, un programa (schedule) para la tasa de aprendizaje y algunos hiperparámetros de entrenamiento:"
      ],
      "metadata": {
        "id": "AhLLrpnRddHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 5\n",
        "batches_per_epoch = len(tokenized_imdb[\"train\"]) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ],
      "metadata": {
        "id": "webJMWK0iQQV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos cargar 'DistilBERT' con TFAutoModelForSequenceClassification junto con el número de etiquetas esperadas y las conversiones de etiquetas:"
      ],
      "metadata": {
        "id": "srZt3SGNeAiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "6dd4be687011489ebc71a4c64b407257",
            "f1b4c67888d9406d8cf8687e6c8aa2ae",
            "5d0d7b7383d04685a5d62daa1f699791",
            "a3e00d8d966d40f487310fb4a48fe1c2",
            "f2798d18e0f84911a9b5a7c3dbd4500e",
            "b175db90e9d34da3af58b39ffbb78c78",
            "bdd89f3d82764bf082ab1199c260cada",
            "bba4f25150144453b8aa6dcc73302b6c",
            "1ffe6e8605264c58b9af3bfa83686c6a",
            "6200b533a5404e8e86da1bc22a6526d3",
            "312d5962957343f9add1eb64d383e2ad"
          ]
        },
        "id": "rWlIEuZ6ihsN",
        "outputId": "b115a384-d304-4a43-8c02-abeed950292f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dd4be687011489ebc71a4c64b407257"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos nuestros datasets (IMDb) al formato tf.data.Dataset con prepare_tf_dataset():"
      ],
      "metadata": {
        "id": "7hAktpGBeWDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    tokenized_imdb[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set = model.prepare_tf_dataset(\n",
        "    tokenized_imdb[\"test\"],\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MSQwOScVnj3",
        "outputId": "6323017c-d76f-43cc-8fba-46e0c8e8b3e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuramos el modelo para entrenar con el método *compile*. Tenga en cuenta que todos los modelos de Transformers tienen una función de pérdida relevante predeterminada para la tarea, por lo que no necesita especificar una a menos queramos."
      ],
      "metadata": {
        "id": "qcC2WxitepiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=optimizer)  # No loss argument!"
      ],
      "metadata": {
        "id": "8fEU0kuzVsU4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las dos últimas cosas que debe configurar antes de comenzar el entrenamiento son calcular la precisión (*accuracy*) de las predicciones y proporcionar una manera de enviar el modelo al Hub. Ambos se realizan mediante llamadas de la librería Keras.\n",
        "\n",
        "Pasamos nuestra función *compute_metrics* a *KerasMetricCallback*:\n"
      ],
      "metadata": {
        "id": "60DiRb33fFOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)"
      ],
      "metadata": {
        "id": "9tb7VhzdVw_Y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E indicamos dónde queremos enviar el modelo y el tokenizador obtenidos en *PushToHubCallback*:"
      ],
      "metadata": {
        "id": "-VZhOzJyfg-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"mi_prezioso_modelo\",\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AdOQkzxVznP",
        "outputId": "c51c829f-f4ee-4823-807e-a60a6764100a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/mdelavilla/mi_prezioso_modelo into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/mdelavilla/mi_prezioso_modelo into local empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, agrupe sus devoluciones de llamada (*callbacks*):"
      ],
      "metadata": {
        "id": "eFXx-jMGf2wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [metric_callback, push_to_hub_callback]"
      ],
      "metadata": {
        "id": "LE7RjF4fXGGP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y973B9LiXIxW",
        "outputId": "8170c36e-6748-4c93-a1ff-d26460f9fcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "  63/1562 [>.............................] - ETA: 27:56:59 - loss: 0.5042"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que se completa el entrenamiento (puede durar... mucho), el modelo se carga automáticamente en el Hub."
      ],
      "metadata": {
        "id": "bzjG5ca4jr6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción\n",
        "\n",
        "Ahora que hemos *ajustado* un modelo, podemos usarlo para realizar inferencias o predicciones. Indica algún texto sobre el que te gustaría realizar inferencias:"
      ],
      "metadata": {
        "id": "9Qy6udAJj-MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
      ],
      "metadata": {
        "id": "pgyLO-EmkT6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La forma más sencilla de probar el modelo ajustado para predicción es usarlo en una *pipeline()*. Creamos una instancia de *pipeline* para el análisis de sentimiento con nuestro modelo y le pasamos el texto:"
      ],
      "metadata": {
        "id": "1Z2eiWcBkYc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"mdelavilla/mi_prezioso_modelo\")\n",
        "classifier(text)"
      ],
      "metadata": {
        "id": "rHyTwBBvksdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O sin el pipeline, paso a paso:"
      ],
      "metadata": {
        "id": "ArptWoHWk9EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mdelavilla/mi_prezioso_modelo\")\n",
        "inputs = tokenizer(text, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "zhHnxxlllF_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"mdelavilla/mi_prezioso_modelo\")\n",
        "logits = model(**inputs).logits"
      ],
      "metadata": {
        "id": "ahDhzhU7lLZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n",
        "model.config.id2label[predicted_class_id]"
      ],
      "metadata": {
        "id": "JomLVwIplVkd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
